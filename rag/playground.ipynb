{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d393ee6",
   "metadata": {},
   "source": [
    "# RAG IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3849ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# pdf loading\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# YT audio loading\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "# langchain-community module(s)\n",
    "from langchain_community.document_loaders.parsers.audio import FasterWhisperParser\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c742b2",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af38afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf loading\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"./pdfs/MachineLearning-Lecture01.pdf\")\n",
    "pages = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc74e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MachineLearning-Lecture01  \\n'\n",
      " 'Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\n'\n",
      " 'learning class. So what I wanna do today is just spend a little time going '\n",
      " 'over the logistics \\n'\n",
      " \"of the class, and then we'll start to talk a bit about machine learning.  \\n\"\n",
      " \"By way of introduction, my name's Andrew Ng and I'll be instructor for this \"\n",
      " 'class. And so \\n'\n",
      " \"I personally work in machine learning, and I've worked on it for about 15 \"\n",
      " 'years now, and \\n'\n",
      " 'I actually think that machine learning is the ')\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "pprint(page.page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246e0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': '',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'page': 0,\n",
      " 'page_label': '1',\n",
      " 'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'source': './pdfs/MachineLearning-Lecture01.pdf',\n",
      " 'title': '',\n",
      " 'total_pages': 22}\n"
     ]
    }
   ],
   "source": [
    "pprint(page.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df399eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=I2ZK3ngNvvI\n",
      "[youtube] I2ZK3ngNvvI: Downloading webpage\n",
      "[youtube] I2ZK3ngNvvI: Downloading tv client config\n",
      "[youtube] I2ZK3ngNvvI: Downloading tv player API JSON\n",
      "[youtube] I2ZK3ngNvvI: Downloading ios player API JSON\n",
      "[youtube] I2ZK3ngNvvI: Downloading m3u8 information\n",
      "[info] I2ZK3ngNvvI: Downloading 1 format(s): 140\n",
      "[download] Destination: ./audios/Advice for machine learning beginners ｜ Andrej Karpathy and Lex Fridman.m4a\n",
      "[download] 100% of    5.36MiB in 00:00:02 at 2.14MiB/s   \n",
      "[FixupM4a] Correcting container of \"./audios/Advice for machine learning beginners ｜ Andrej Karpathy and Lex Fridman.m4a\"\n",
      "[ExtractAudio] Not converting audio ./audios/Advice for machine learning beginners ｜ Andrej Karpathy and Lex Fridman.m4a; file is already in target format m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-14 22:45:32.751] [ctranslate2] [thread 41436] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n",
      "[2025-05-14 22:46:13.574] [ctranslate2] [thread 41436] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n"
     ]
    }
   ],
   "source": [
    "# YT audio loading\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=I2ZK3ngNvvI'    # Hardik Pandya\n",
    "save_dir = './audios'\n",
    "yt_loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    FasterWhisperParser(model_size='tiny', device='cpu')\n",
    ")\n",
    "docs = yt_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57dc046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"You're one of the greatest teachers of machine learning AI ever from CS231N \"\n",
      " 'to today. What advice would you give to beginners interested in getting into '\n",
      " 'machine learning? Beginners are often focused on like what to do and I think '\n",
      " 'the focus should be more like how much you do. So I am kind of like believer '\n",
      " 'on the high level in this 10,000 hours kind of concept where you just kind '\n",
      " 'of have to just pick the things where you can spend time and you care about '\n",
      " \"and you're interested in. You literally have to put in 10,000 hours of work. \"\n",
      " \"It doesn't even like matter as much like where you put it and you'll iterate \"\n",
      " \"and you'll improve and you'll waste some time. I don't know if there's a \"\n",
      " \"better way. You need to put in 10,000 hours. But I think it's actually \"\n",
      " \"really nice because I feel like there's some sense of determinism about \"\n",
      " 'being an expert at a thing if you spend 10,000 hours. You can literally pick '\n",
      " 'an arbitrary thing and I think if you spend 10,000 hours of deliberate '\n",
      " 'effort and work, you act')\n"
     ]
    }
   ],
   "source": [
    "final_dialouge = \"\"\n",
    "for doc in docs:    \n",
    "    page_content = doc.page_content.strip()\n",
    "    final_dialouge += page_content + ' '\n",
    "\n",
    "\n",
    "pprint(final_dialouge[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fd8c2",
   "metadata": {},
   "source": [
    "## LOCAL PDF RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f8c9f",
   "metadata": {},
   "source": [
    "yt@pixegami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52b7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader    # langchain.document_loader depricated\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain_ollama import OllamaEmbeddings    # ollama embeddings\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac41a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./pdfs\"\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d8936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents: list[Document]):    # type hinting\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cf398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding():\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")    # best embedding model avialable in ollama\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe6a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = load_documents()\n",
    "chunks = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325dd89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5039be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'author': '',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'title': '',\n",
      " 'source': 'pdfs/MachineLearning-Lecture01.pdf',\n",
      " 'total_pages': 22,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b495af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "    curr_chunk_idx = 0\n",
    "    prev_page_id = \"\"\n",
    "\n",
    "    for chunk in chunks:\n",
    "        curr_page_id = f\"{chunk.metadata['source']}:{chunk.metadata['page']}\"\n",
    "        \n",
    "        if curr_page_id == prev_page_id:\n",
    "            curr_chunk_idx += 1\n",
    "        else:\n",
    "            curr_chunk_idx = 0    # reset\n",
    "\n",
    "        prev_page_id = curr_page_id\n",
    "        chunk_id = f\"{curr_page_id}:{curr_chunk_idx}\"\n",
    "\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_ids = calculate_chunk_ids(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4aaf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdfs/MachineLearning-Lecture01.pdf:11:2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_with_ids[50].metadata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6e2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating database\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"rag_tutorial\"\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    db = Chroma(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding_function=get_embedding(),\n",
    "        persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    \n",
    "    curr_items = db.get(include=[])    # ids included by default\n",
    "    curr_ids = set(curr_items[\"ids\"])\n",
    "    print(f\"Current Documents: {len(curr_items)}\")\n",
    "\n",
    "    # adding docs not in db\n",
    "    new_chunks = []\n",
    "    new_chunk_ids = []\n",
    "    for chunk in chunks:\n",
    "        if not chunk.page_content.strip():\n",
    "            print(f\"[WARNING] Empty content for chunk id: {chunk.metadata['id']}\")\n",
    "\n",
    "        else:\n",
    "            if chunk.metadata['id'] not in curr_ids:\n",
    "                new_chunks.append(chunk)\n",
    "                new_chunk_ids.append(chunk.metadata['id'])\n",
    "\n",
    "    if new_chunks:\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "\n",
    "    else:\n",
    "        print(\"NO VALID CHUNKS TO AVAILABLE!\")\n",
    "    # db.persist() [automatically done in newer versions]\n",
    "\n",
    "    print(f\"Newly Added Documents: {len(new_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a297cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Documents: 7\n",
      "Newly Added Documents: 153\n"
     ]
    }
   ],
   "source": [
    "add_to_chroma(chunks_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b1700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import  ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "# reference: [https://python.langchain.com/docs/integrations/llms/ollama/]\n",
    "\n",
    "def query_rag(query_txt: str):\n",
    "\n",
    "    db = Chroma(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding_function=get_embedding(),\n",
    "        persist_directory=CHROMA_PATH\n",
    "    )\n",
    "\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    Answer any question only on the following context:\n",
    "    {context}\n",
    "\n",
    "    ---\n",
    "    Answer the question based on the above context: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    # retrieve most relevant chunks to our question\n",
    "    results = db.similarity_search_with_score(query_txt, k=5)     \n",
    "\n",
    "    context_txt = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_txt, question=query_txt)\n",
    "\n",
    "    model = OllamaLLM(model=\"llama3.2:3b\")\n",
    "    response_txt = model.invoke(prompt)\n",
    "    print(response_txt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _ in results]\n",
    "    print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a77658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, Andrew Ng taught the following topics:\n",
      "\n",
      "1. Logistics of the class\n",
      "2. Introduction to machine learning (with some discussion about his personal experience and excitement about machine learning)\n",
      "3. Convex optimization (to be covered in discussion sections)\n",
      "4. Hidden Markov models (a type of machine learning algorithm for modeling time series, to be covered in discussion sections)\n",
      "\n",
      "Note that these topics are mentioned as part of the lecture outline or discussed during the class, but not necessarily covered in detail in the main lectures.\n",
      "['pdfs/MachineLearning-Lecture01.pdf:9:3', 'pdfs/MachineLearning-Lecture01.pdf:0:0', 'pdfs/MachineLearning-Lecture01.pdf:1:1', 'pdfs/MachineLearning-Lecture01.pdf:9:0', 'pdfs/MachineLearning-Lecture01.pdf:8:4']\n"
     ]
    }
   ],
   "source": [
    "query_rag(\"Which topic did Anderw NG Taught in the lecture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e71218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
