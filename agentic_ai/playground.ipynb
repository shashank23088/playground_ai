{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0d4511",
   "metadata": {},
   "source": [
    "## Pydantic Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6c873",
   "metadata": {},
   "source": [
    "- data validation\n",
    "- define structure and validate data at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c78781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    city: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18cd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Krish' age=35 city='Bangalore'\n",
      "<class '__main__.Person'>\n"
     ]
    }
   ],
   "source": [
    "person1 = Person(name=\"Krish\", age=35, city=\"Bangalore\")\n",
    "print(person1)\n",
    "print(type(person1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb26f53",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Person\ncity\n  Input should be a valid string [type=string_type, input_value=12, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m person2 = \u001b[43mPerson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mKrish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(person2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Person\ncity\n  Input should be a valid string [type=string_type, input_value=12, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "person2 = Person(name=\"Krish\", age=35, city=12)\n",
    "print(person2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368cb99",
   "metadata": {},
   "source": [
    "- Model with optional fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5fad504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Employee(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    department: str\n",
    "\n",
    "    # optional with default values already set\n",
    "    salary: Optional[float] = None\n",
    "    is_active: Optional[bool] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b001e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='John' department='IT' salary=None is_active=True\n"
     ]
    }
   ],
   "source": [
    "emp1 = Employee(id=1, name=\"John\", department=\"IT\")\n",
    "print(emp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec0d83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=2 name='Jane' department='HR' salary=50000.0 is_active=True\n"
     ]
    }
   ],
   "source": [
    "# only type casting from int to float\n",
    "emp2 = Employee(id=2, name=\"Jane\", department=\"HR\", salary=50000)\n",
    "print(emp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58492c",
   "metadata": {},
   "source": [
    "- Model with List values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6fc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classroom(BaseModel):\n",
    "    room_number: str\n",
    "    students: List[str]\n",
    "    capacity: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d696a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_number='A612' students=['Alice', 'Bob', 'Jamie'] capacity=20\n"
     ]
    }
   ],
   "source": [
    "classroom1 = Classroom(\n",
    "    room_number=\"A612\",\n",
    "\n",
    "    # type casting from tuple/set to list will happen\n",
    "    students=('Alice', 'Bob', 'Jamie'),\n",
    "    \n",
    "    capacity=20\n",
    ")\n",
    "print(classroom1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ee91a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for Classroom\n",
      "students.1\n",
      "  Input should be a valid string [type=string_type, input_value=42, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    invalid_classroom = Classroom(\n",
    "        room_number=\"A612\",\n",
    "        students= [\"Shashank\" ,42],\n",
    "        capacity=30\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2505cc",
   "metadata": {},
   "source": [
    "- Complex Structure Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efe1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    zip_code: int\n",
    "\n",
    "\n",
    "class Customer(BaseModel): \n",
    "    customer_id: int\n",
    "    name: str\n",
    "    address: Address "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0deafc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id=1 name='Hix' address=Address(street='Kh Road', city='Gandhinagar', zip_code=382028)\n"
     ]
    }
   ],
   "source": [
    "customer1 = Customer(\n",
    "    customer_id=1,\n",
    "    name=\"Hix\",\n",
    "    address={\"street\": \"Kh Road\", \"city\": \"Gandhinagar\", \"zip_code\": \"382028\"}\n",
    "    # automatic type casting from str to int\n",
    ")\n",
    "\n",
    "print(customer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34115c12",
   "metadata": {},
   "source": [
    "- Pydantic Fields: Customization and Constraints (Specify validation rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4561954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item(BaseModel):\n",
    "    name: str=Field(min_length=2, max_length=50)\n",
    "    price: float=Field(gt=0, le=1000)\n",
    "    quantity: int=Field(ge=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be029f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Book' price=45.43 quantity=1\n"
     ]
    }
   ],
   "source": [
    "item1 = Item(name=\"Book\", price=45.43, quantity=1)\n",
    "print(item1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d0235",
   "metadata": {},
   "source": [
    "- Fields with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65ea363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    username: str=Field(description=\"Unique username for the user\")\n",
    "    age: int=Field(default=18, description=\"User age, defaults to 18\")\n",
    "    email: str=Field(default=\"user@email.com\", description=\"Default Email Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f83137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username='alice' age=18 email='user@email.com'\n"
     ]
    }
   ],
   "source": [
    "user1 = User(username=\"alice\")\n",
    "print(user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ac0802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username='bob' age=25 email='bob@domain.com'\n"
     ]
    }
   ],
   "source": [
    "user2 = User(username=\"bob\", age=25, email=\"bob@domain.com\")\n",
    "print(user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6528be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'username': {'description': 'Unique username for the user',\n",
       "   'title': 'Username',\n",
       "   'type': 'string'},\n",
       "  'age': {'default': 18,\n",
       "   'description': 'User age, defaults to 18',\n",
       "   'title': 'Age',\n",
       "   'type': 'integer'},\n",
       "  'email': {'default': 'user@email.com',\n",
       "   'description': 'Default Email Address',\n",
       "   'title': 'Email',\n",
       "   'type': 'string'}},\n",
       " 'required': ['username'],\n",
       " 'title': 'User',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0d1ae",
   "metadata": {},
   "source": [
    "# Langchain and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5428",
   "metadata": {},
   "source": [
    "- Langchain, Langsmith, Langserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16564244",
   "metadata": {},
   "source": [
    "- basic components: prompt templates, models, output parsers\n",
    "- build app with langchain\n",
    "- trace app with langsmith\n",
    "- serve app with langserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6f38c",
   "metadata": {},
   "source": [
    "- .env file: contains API keys(openai, langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da79324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    WebBaseLoader, \n",
    "    ArxivLoader,\n",
    "    WikipediaLoader\n",
    ")\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa62504",
   "metadata": {},
   "source": [
    "### DATA INGESTION\n",
    "https://python.langchain.com/docs/integrations/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74bee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.document_loaders.text.TextLoader object at 0x792cbc136900>\n"
     ]
    }
   ],
   "source": [
    "# text loader\n",
    "txt_loader = TextLoader('./data/minerva_report.txt')\n",
    "print(txt_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f567ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_documents = txt_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4ce7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './data/minerva_report.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(txt_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef4b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Report on Minerva Academy and Its Current Form (as of July 28, 2025)\n",
      "Overview\n",
      "\n",
      "Minerva Academy is a prominent institution with multiple branches specializing in sports (notably football), teacher education, and distance learning. Its flagship, Minerva Academy FC, based in Mohali, Punjab, is widely recognized as one of India’s most successful youth football academies, while their educational wings operate B.Ed. and distance education programs across teaching and professional domains.\n",
      "Foo\n"
     ]
    }
   ],
   "source": [
    "print(txt_documents[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf loader\n",
    "pdf_loader = PyPDFLoader(\"./data/resume.pdf\")\n",
    "pdf_documents = pdf_loader.load()    # load each page separately\n",
    "len(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e2bc9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.26',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2025-07-04T09:12:57+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2025-07-04T09:12:57+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': './data/resume.pdf',\n",
       " 'total_pages': 2,\n",
       " 'page': 0,\n",
       " 'page_label': 'i'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1805a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shashank Sharma\n",
      "Department of Computer Science & Engineering /envel⌢peshashank.0901sharma@gmail.com / ♂phone+91-8490849270\n",
      "Indraprastha Institute of Information Technology, Delhi /linkedinshashankgsharma / /githubshashank23088\n",
      "EDUCATION\n",
      "Year Degree/Certificate Institute CPI/%\n",
      "2023-2025 M.Tech/CSE (AI Specialization) Indraprastha Institute of Information Technology , Delhi 8.07/10\n",
      "2019-2023 B.E/Information & Communication\n",
      "Technology\n",
      "Adani Institute of Infrastructure Engineering,\n",
      "Ahmedabad (Gujarat)\n",
      "9.22/10\n",
      "2019 CBSE(HSC) Kendriya Vidyalaya, Gandhinagar (Gujarat) 84.2%\n",
      "2017 CBSE(SSC) Kendriya Vidyalaya, Gandhinagar (Gujarat) 10/10\n",
      "PUBLICATIONS\n",
      "• Pulse of the Crowd: Quantifying Crowd Energy through Audio and Video Analysis\n",
      "IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR), 2024.\n",
      "◦ Developed a pipeline to score videos based on perceived crowd energy using audio and video analysis.\n",
      "◦ Utilized STEERER for crowd density maps and ResNet50, VGG18, AlexN\n"
     ]
    }
   ],
   "source": [
    "print(pdf_documents[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8d7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web-based loader\n",
    "url = \"https://timesofindia.indiatimes.com/business/india-business/tcs-layoffs-biggest-ever-for-indian-it-artificial-intelligence-not-to-blame-for-difficult-decision-top-10-things-to-know-about-mass-sackings/articleshow/122949729.cms\"\n",
    "\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=url,\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "        class_=(\"pZFl7\", \"heightCalc\")\n",
    "    ))\n",
    ")\n",
    "\n",
    "web_documents = web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc1da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'https://timesofindia.indiatimes.com/business/india-business/tcs-layoffs-biggest-ever-for-indian-it-artificial-intelligence-not-to-blame-for-difficult-decision-top-10-things-to-know-about-mass-sackings/articleshow/122949729.cms'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(web_documents))\n",
    "web_documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd032f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"tails regarding the calculation of the 2% reduction, the implementation process for the staff reductions, or whether additional rounds of job cuts would follow in subsequent periods.9. Tough IT Sector EnvironmentThe Indian IT sector is facing unprecedented job cuts, mirroring practices commonly seen in US companies, causing widespread concern throughout the industry. The combination of global economic uncertainties and disruptions caused by artificial intelligence technology continues to affect business demand.10. Global Trends of LayoffsBased on the data from Layoffs.fyi, a platform monitoring global tech industry redundancies, more than 80,000 technology sector employees have lost their jobs across 169 companies in 2025.2024, witnessed approximately 150,000 job losses spanning 551 technology firms. These figures reflect both worldwide economic challenges and ongoing discussions within the technology sector regarding artificial intelligence's influence on employment opportunities and w\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(web_documents[0].page_content))\n",
    "web_documents[0].page_content[6000:7001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4201a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv as data-source\n",
    "doc_id = \"2407.03305\"\n",
    "arxiv_loader = ArxivLoader(query=doc_id, load_max_docs=2)\n",
    "arxiv_documents = arxiv_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9be09a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-07-05',\n",
       " 'Title': 'Advanced Smart City Monitoring: Real-Time Identification of Indian Citizen Attributes',\n",
       " 'Authors': 'Shubham Kale, Shashank Sharma, Abhilash Khuntia',\n",
       " 'Summary': \"This project focuses on creating a smart surveillance system for Indian\\ncities that can identify and analyze people's attributes in real time. Using\\nadvanced technologies like artificial intelligence and machine learning, the\\nsystem can recognize attributes such as upper body color, what the person is\\nwearing, accessories they are wearing, headgear, etc., and analyze behavior\\nthrough cameras installed around the city.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(arxiv_documents))\n",
    "arxiv_documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99093c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Smart City Monitoring: Real-Time\n",
      "Identification of Indian Citizen Attributes\n",
      "Shubham Kale\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "shubham23094@iiitd.ac.in\n",
      "Shashank Sharma\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "shashank23088@iiitd.ac.in\n",
      "Abhilash Khuntia\n",
      "M.Tech CSE\n",
      "Dept. of CSE\n",
      "IIIT Delhi\n",
      "abhilash23007@iiitd.ac.in\n",
      "Abstract—This project focuses on creating a smart surveillance\n",
      "system for Indian cities that can identify and analyze people’s\n",
      "attributes in real time. Using advanced technologies like artificial\n",
      "intelligence and machine learning, the system can recognize\n",
      "attributes such as upper body color what the person is wearing,\n",
      "accessories that he or she is wearing, headgear check, etc.,\n",
      "and analyze behavior through cameras installed around the\n",
      "city. We have provided all our code for our experiments at\n",
      "https://github.com/abhilashk23/vehant-scs-par We will be contin-\n",
      "uously updating the above GitHub repo to keep up-to-date with\n",
      "the most cutting-edge work on person attribute recognition.\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_documents[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9536e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia as data source\n",
    "wikipedia_loader = WikipediaLoader(query=\"Huffman coding\", load_max_docs=2)\n",
    "wikipedia_docs = wikipedia_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9a2fab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Huffman coding',\n",
       " 'summary': 'In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code is Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper \"A Method for the Construction of Minimum-Redundancy Codes\".\\nThe output from Huffman\\'s algorithm can be viewed as a variable-length code table for encoding a source symbol (such as a character in a file).  The algorithm derives this table from the estimated probability or frequency of occurrence (weight) for each possible value of the source symbol.  As in other entropy encoding methods, more common symbols are generally represented using fewer bits than less common symbols.  Huffman\\'s method can be efficiently implemented, finding a code in time linear to the number of input weights if these weights are sorted.  However, although optimal among methods encoding symbols separately, Huffman coding is not always optimal among all compression methods – it is replaced with arithmetic coding or asymmetric numeral systems if a better compression ratio is required.\\n\\n',\n",
       " 'source': 'https://en.wikipedia.org/wiki/Huffman_coding'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(wikipedia_docs))\n",
    "wikipedia_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7a7eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In computer science and information theory, a Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The process of finding or using such a code is Huffman coding, an algorithm developed by David A. Huffman while he was a Sc.D. student at MIT, and published in the 1952 paper \"A Method for the Construction of Minimum-Redundancy Codes\".\n",
      "The output from Huffman's algorithm can be viewed as a variable-length code table for encoding a source symbol (such as a character in a file).  The algorithm derives this table from the estimated probability or frequency of occurrence (weight) for each possible value of the source symbol.  As in other entropy encoding methods, more common symbols are generally represented using fewer bits than less common symbols.  Huffman's method can be efficiently implemented, finding a code in time linear to the number of input weights if these weights are sorted.  However, although optimal among methods encoding\n"
     ]
    }
   ],
   "source": [
    "print(wikipedia_docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b50c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
